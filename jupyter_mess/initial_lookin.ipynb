{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f499c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from unidecode import unidecode\n",
    "import regex as re\n",
    "\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 4000\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "\n",
    "cwd = !pwd\n",
    "cwd = Path(str(cwd[0]))\n",
    "file_name = \"murphys_clan_new.txt\"\n",
    "raw_file_path = cwd.parent / \"raw_export\" / file_name\n",
    "\n",
    "\n",
    "def starts_with_timestamp(line):\n",
    "    pattern = '\\d{2}\\/\\d{2}\\/\\d{4}, \\d{2}:\\d{2} - '\n",
    "    result = re.match(pattern, line)\n",
    "    if result:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_convo_as_list(raw_file_path):\n",
    "    cleaned_data = []\n",
    "    with open(raw_file_path, encoding=\"utf-8\") as f:\n",
    "        message_buffer = []\n",
    "        f.readline() # Skip first line as never a message.\n",
    "        while True:\n",
    "            line = f.readline() \n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if starts_with_timestamp(line):\n",
    "                if message_buffer:\n",
    "                    cleaned_data.append(\"\\n\".join(message_buffer))\n",
    "                message_buffer.clear()\n",
    "                message_buffer.append(line)\n",
    "            else:\n",
    "                message_buffer.append(line)\n",
    "    return cleaned_data\n",
    "\n",
    "def get_emoji_series(raw_series):\n",
    "    emoji_series = pd.Series(raw_series, name='emoji').apply(extract_emojis)\n",
    "    return emoji_series\n",
    "\n",
    "def get_raw_series(raw_text):\n",
    "    return pd.Series(raw_text, name='raw').apply(lambda x: unidecode(x))\n",
    "\n",
    "def extract_emojis(s):\n",
    "    return [c for c in s if c in emoji.UNICODE_EMOJI['en']]\n",
    "\n",
    "def process_dataframe(raw_series, rename_dict):\n",
    "    df = raw_series.str.extract('(\\d{2}\\/\\d{2}\\/\\d{4}, \\d{2}:\\d{2})?( - .*|.*)')\n",
    "    df.rename(columns={0 :'datetime', 1 :'other'}, inplace=True)\n",
    "    df = process_datetime(df)\n",
    "    df[[\"sender\", \"message\"]] = df[\"other\"].str.split(\": \", n=1, expand=True)\n",
    "    df.drop(\"other\", inplace=True, axis=1)\n",
    "    df.dropna(inplace=True)\n",
    "    clean_sender(df, rename_dict)\n",
    "    return df\n",
    "\n",
    "def process_datetime(df):\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format='%d/%m/%Y, %H:%M')\n",
    "    df['hour'] = df['datetime'].dt.strftime('%H').astype('int64')\n",
    "    return df\n",
    "\n",
    "def add_stats(df):\n",
    "    df['word_count'] = df['message'].str.count(r'(?:(?<=\\s))\\w*')\n",
    "    df['letter_count'] = df['message'].apply(lambda s : len(s))\n",
    "    return df\n",
    "    \n",
    "    \n",
    "\n",
    "def clean_sender(df, rename_dict):\n",
    "    df['sender'] = df['sender'].str.replace(' - ', '')\n",
    "    df['sender'].replace(to_replace=rename_dict, inplace=True)\n",
    "    return df\n",
    "\n",
    "def process_emoji_df(df):\n",
    "    df = df.copy()\n",
    "    df = df.explode('emoji')\n",
    "    df.drop(['message'])\n",
    "    return df\n",
    "\n",
    "rename_dict = {'+44 7964 738500':'Mum'}\n",
    "raw_text = get_convo_as_list(raw_file_path)\n",
    "raw_series = get_raw_series(raw_text) \n",
    "df = process_dataframe(raw_series, rename_dict)    \n",
    "df = add_stats(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba540fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_word_length'] = df['letter_count'] / df['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91fe2d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "tokens = df.message.apply(lambda x: tokenizer(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab3d51",
   "metadata": {},
   "source": [
    "## Look see of initial read in method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "814a51bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nah...Just a dusting'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fd4716c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ml\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l' is not defined"
     ]
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a28c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hour.hist(bins=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a36c17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.sender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcae5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sender.hist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convo-analytics",
   "language": "python",
   "name": "convo-analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
